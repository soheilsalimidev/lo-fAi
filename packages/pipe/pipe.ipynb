{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "sys.path.append(\"./../model/src/tokenizer/\")\n",
    "sys.path.append(\"./../inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/transformers/utils/generic.py:482: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/arthur/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/arthur/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/transformers/utils/generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/arthur/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/arthur/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    }
   ],
   "source": [
    "from transformers import MusicgenForConditionalGeneration\n",
    "\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/musicgen-small\")\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "\n",
    "# text = [input('prompts ?').strip()]\n",
    "\n",
    "inputs = processor(\n",
    "    text=['80s pop track with bassy drums and synth'],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs.to(device), do_sample=True, guidance_scale=3, max_new_tokens=256)\n",
    "\n",
    "scipy.io.wavfile.write(\"musicgen_out.wav\", rate=sampling_rate,\n",
    "                       data=audio_values[0, 0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Coremltools is not installed. If you plan to use a CoreML Saved Model, reinstall basic-pitch with `pip install 'basic-pitch[coreml]'`\n",
      "WARNING:root:onnxruntime is not installed. If you plan to use an ONNX Model, reinstall basic-pitch with `pip install 'basic-pitch[onnx]'`\n",
      "WARNING:root:Tensorflow is not installed. If you plan to use a TF Saved Model, reinstall basic-pitch with `pip install 'basic-pitch[tf]'`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting MIDI for musicgen_out.wav...\n",
      "\n",
      "\n",
      "  Creating midi...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "  ðŸš¨ musicgen_out_basic_pitch.mid already exists and would be overwritten. Skipping output files for musicgen_out.wav.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_pitch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ICASSP_2022_MODEL_PATH\n\u001b[1;32m      3\u001b[0m basic_pitch_model \u001b[38;5;241m=\u001b[39m Model(ICASSP_2022_MODEL_PATH)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpredict_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmusicgen_out.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_midi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_model_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_notes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msonify_midi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmodel_or_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasic_pitch_model\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/basic_pitch/inference.py:587\u001b[0m, in \u001b[0;36mpredict_and_save\u001b[0;34m(audio_path_list, output_directory, save_midi, sonify_midi, save_model_outputs, save_notes, model_or_model_path, onset_threshold, frame_threshold, minimum_note_length, minimum_frequency, maximum_frequency, multiple_pitch_bends, melodia_trick, debug_file, sonification_samplerate, midi_tempo)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/basic_pitch/inference.py:561\u001b[0m, in \u001b[0;36mpredict_and_save\u001b[0;34m(audio_path_list, output_directory, save_midi, sonify_midi, save_model_outputs, save_notes, model_or_model_path, onset_threshold, frame_threshold, minimum_note_length, minimum_frequency, maximum_frequency, multiple_pitch_bends, melodia_trick, debug_file, sonification_samplerate, midi_tempo)\u001b[0m\n\u001b[1;32m    559\u001b[0m     midi_path \u001b[38;5;241m=\u001b[39m build_output_path(audio_path, output_directory, OutputExtensions\u001b[38;5;241m.\u001b[39mMIDI)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     midi_data\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(midi_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/basic_pitch/inference.py:559\u001b[0m, in \u001b[0;36mpredict_and_save\u001b[0;34m(audio_path_list, output_directory, save_midi, sonify_midi, save_model_outputs, save_notes, model_or_model_path, onset_threshold, frame_threshold, minimum_note_length, minimum_frequency, maximum_frequency, multiple_pitch_bends, melodia_trick, debug_file, sonification_samplerate, midi_tempo)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_midi:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         midi_path \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_output_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputExtensions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMIDI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/AItuneCraft/lib/python3.10/site-packages/basic_pitch/inference.py:385\u001b[0m, in \u001b[0;36mbuild_output_path\u001b[0;34m(audio_path, output_directory, output_type)\u001b[0m\n\u001b[1;32m    382\u001b[0m generating_file_message(output_type\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  ðŸš¨ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(output_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists and would be overwritten. Skipping output files for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n",
      "\u001b[0;31mOSError\u001b[0m:   ðŸš¨ musicgen_out_basic_pitch.mid already exists and would be overwritten. Skipping output files for musicgen_out.wav."
     ]
    }
   ],
   "source": [
    "from basic_pitch.inference import predict_and_save, Model\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "basic_pitch_model = Model(ICASSP_2022_MODEL_PATH)\n",
    "\n",
    "\n",
    "predict_and_save(audio_path_list=['musicgen_out.wav'],\n",
    "                 save_midi=True,\n",
    "                 output_directory='./',\n",
    "                 save_model_outputs=False,\n",
    "                 save_notes=False,\n",
    "                 sonify_midi=False,\n",
    "                 model_or_model_path=basic_pitch_model\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.2.5\n",
      "Copyright (C) 2000-2022 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "Rendering audio to file '/mnt/c/Users/sohei/OneDrive/Desktop/AItuneCraft/packages/inference/soundFont/output.flac'..\n",
      "FluidSynth runtime version 2.2.5\n",
      "Copyright (C) 2000-2022 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "Rendering audio to file '/mnt/c/Users/sohei/OneDrive/Desktop/AItuneCraft/packages/inference/soundFont/output.flac'..\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "from inference.inferRWKV import mixTheSongs\n",
    "from model.src.tokenizer.midi_to_str import convert_midi_bytes_to_str\n",
    "\n",
    "with open('./musicgen_out_basic_pitch.mid', \"rb\") as f:\n",
    "    midi = convert_midi_bytes_to_str(None, ('', f.read()))\n",
    "    songPath = mixTheSongs(60, midi[1][0], 200) # type: ignore\n",
    "    Audio(filename=songPath, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AItuneCraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
